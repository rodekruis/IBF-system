library(shiny)
library(janitor)
library(tidyverse)
library(lubridate)
library(plotly)
library(shinydashboard)
library(sf)
library(leaflet)
library(readr)
library(httr)

source('r_resources/plot_functions.R')
source('r_resources/predict_functions.R')
source('r_resources/Geo_settings.R')

#---------------------- setting -------------------------------

settings <- country_settings
url<- parse_url(url_geonode)

Country="Ethiopia"
for (elm in  names(eval(parse(text=paste("settings$",Country,sep=""))))){
  url$query <- list(service = "WFS",version = "2.0.0",request = "GetFeature",
                    typename = eval(parse(text=paste("settings$",Country,"$",elm,sep=""))),
                    outputFormat = "application/json")
  request <- build_url(url)
  data_read <- st_read(request)
  assign(paste0(Country,"_",elm),data_read)
}

Country="Kenya"
for (elm in  names(eval(parse(text=paste("settings$",Country,sep=""))))){
  url$query <- list(service = "WFS",version = "2.0.0",request = "GetFeature",
                    typename = eval(parse(text=paste("settings$",Country,"$",elm,sep=""))),
                    outputFormat = "application/json")
  request <- build_url(url)
  data_read <- st_read(request)
  assign(paste0(Country,"_",elm),data_read)
}

Country="Uganda"
for (elm in  names(eval(parse(text=paste("settings$",Country,sep=""))))){
  url$query <- list(service = "WFS",version = "2.0.0",request = "GetFeature",
                    typename = eval(parse(text=paste("settings$",Country,"$",elm,sep=""))),
                    outputFormat = "application/json")
  request <- build_url(url)
  data_read <- st_read(request)
  assign(paste0(Country,"_",elm),data_read)
}

# swi <- read.csv("data/ethiopia_admin3_swi_all.csv", stringsAsFactors = F, colClasses = c("character", "character", "numeric", "numeric", "numeric"))
#ethiopia_impact <- read.csv("data/Eth_impact_data2.csv", stringsAsFactors = F, sep=";")

ethiopia_impact <- read_delim("data/Ethiopia_impact.csv", ",", escape_double = FALSE, trim_ws = TRUE)




# to be replaced by data imorted from Geonode 
eth_admin3 <- Ethiopia_admin3
eth_admin3 <- sf::read_sf("shapes/ETH_Admin3_2019.shp") 
eth_admin3 <- st_transform(eth_admin3, crs = "+proj=longlat +datum=WGS84")

glofas_raw <- read_csv("data/GLOFAS_fill_allstation_.csv") %>% rename(date = time)
glofas_mapping <- read.csv("data/Eth_affected_area_stations2.csv", stringsAsFactors = F)
point_rainfall <- read_csv('data/Impact_Hazard_catalog.csv') %>% clean_names()

rp_glofas_station <- read_csv('data/rp_glofas_station.csv') %>% clean_names()


# Clean impact and keep relevant columns
df_impact_raw <- ethiopia_impact %>%
  clean_names() %>%
  mutate(date = dmy(date),
         pcode = str_pad(as.character(pcode), 6, "left", "0")) %>%
  dplyr::select(region, zone, wereda, pcode, date) %>%
  unique() %>%
  arrange(pcode, date)

# Used to join against
all_days <- tibble(date = seq(min(df_impact_raw$date, na.rm=T) - 60, max(df_impact_raw$date, na.rm=T) + 60, by="days"))

# Clean GLOFAS mapping
glofas_mapping <- glofas_mapping %>%
  dplyr::select(-Z_NAME) %>%
  gather(station_i, station_name, -W_NAME) %>%
  dplyr::filter(!is.na(station_name)) %>%
  dplyr::select(-station_i) %>%
  left_join(ethiopia_impact %>% dplyr::select(Wereda, pcode) %>% unique(), by = c("W_NAME" = "Wereda")) %>%
  mutate(pcode = str_pad(as.character(pcode), 6, "left", "0")) %>%
  dplyr::filter(!is.na(pcode))

# Clean glofas
glofas_raw <- glofas_raw %>%
  dplyr::filter(
    date >= min(df_impact_raw$date, na.rm=T) - 60,
    date <= max(df_impact_raw$date, na.rm=T) + 60)

glofas_raw <- expand.grid(all_days$date, unique(glofas_raw$station)) %>%
  rename(date = Var1, station = Var2) %>%
  left_join(glofas_raw %>% dplyr::select(date, dis, dis_3, dis_7, station), by = c("date", "station")) %>% arrange(station, date) %>%
  arrange(station, date) %>%
  group_by(station) %>%
  fill(dis, dis_3, dis_7, .direction="down") %>%
  fill(dis, dis_3, dis_7, .direction="up") %>%
  ungroup()

rainfall_raw <- point_rainfall %>%
  left_join(df_impact_raw %>% dplyr::select(pcode, zone), by = "zone") %>%
  group_by(pcode, date) %>%
  summarise(rainfall = mean(rainfall, na.rm=T))

# Clean rainfall - CHIRPS, kept for legacy
# rainfall_raw <- rainfall_raw %>%
#   mutate(pcode = str_pad(pcode, 6, "left", 0)) %>%
#   filter(
#     date >= min(df_impact_raw$date, na.rm=T) - 60,
#     date <= max(df_impact_raw$date, na.rm=T) + 60)

# # SWI, kept for legacy
# swi_raw <- swi %>%
#   mutate(date = ymd(date))
# swi_raw <- swi_raw %>%
#   gather(depth, swi, -pcode, -date)

# Determine floods per Wereda for map
floods_per_wereda <- df_impact_raw %>%
  group_by(region, wereda, pcode) %>%
  summarise(
    n_floods = n()
  ) %>%
  arrange(-n_floods) %>%
  ungroup()

eth_admin3 <- eth_admin3 %>%
  left_join(floods_per_wereda %>% dplyr::select(pcode, n_floods), by = c("Pcode" = "pcode")) %>% dplyr::filter(!is.na(n_floods))

flood_palette <- colorNumeric(palette = "YlOrRd", domain = floods_per_wereda$n_floods)